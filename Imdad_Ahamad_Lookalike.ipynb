{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "WB3BzIkrPnwz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "customers = pd.read_csv(\"Customers.csv\")\n",
        "products = pd.read_csv(\"Products.csv\")"
      ],
      "metadata": {
        "id": "gPGT-sOLP-tI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "customers_path = 'Customers.csv'\n",
        "products_path = 'Products.csv'"
      ],
      "metadata": {
        "id": "3SuxF8BmQGUq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    customers_data = pd.read_csv(customers_path)\n",
        "    products_data = pd.read_csv(products_path)\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "hzpe3_95Sb5d"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a dummy transaction matrix (Customer x Product)\n",
        "dummy_transactions = {\n",
        "    'CustomerID': ['C0001', 'C0002', 'C0003', 'C0004', 'C0005'],\n",
        "    'P001': [1, 0, 1, 0, 1],\n",
        "    'P002': [0, 1, 0, 1, 0],\n",
        "    'P003': [1, 1, 1, 0, 0],\n",
        "    'P004': [0, 0, 1, 1, 0],\n",
        "    'P005': [1, 0, 0, 1, 1]\n",
        "}\n",
        "transaction_data = pd.DataFrame(dummy_transactions)"
      ],
      "metadata": {
        "id": "_ohugSu-Sbtd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge customer and transaction data\n",
        "try:\n",
        "    if 'CustomerID' not in customers_data.columns or 'CustomerID' not in transaction_data.columns:\n",
        "        raise KeyError(\"'CustomerID' column is missing in one of the datasets.\")\n",
        "    customer_transactions = pd.merge(customers_data, transaction_data, on='CustomerID', how='inner')\n",
        "except KeyError as e:\n",
        "    print(f\"Error: {e}. Ensure that 'CustomerID' exists in both datasets.\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "pNRsyotySpbE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "# One-hot encode categorical variables (Region)\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "try:\n",
        "    if 'Region' not in customer_transactions.columns:\n",
        "        raise KeyError(\"'Region' column is missing in the dataset.\")\n",
        "    encoder = OneHotEncoder(sparse_output=False)\n",
        "    region_encoded = encoder.fit_transform(customer_transactions[['Region']])\n",
        "    region_df = pd.DataFrame(region_encoded, columns=encoder.get_feature_names_out(['Region']))\n",
        "except KeyError as e:\n",
        "    print(f\"Error: {e}. Ensure that 'Region' exists in the dataset.\")\n",
        "    exit()\n"
      ],
      "metadata": {
        "id": "Ty4zhvghSpYA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine numerical and categorical features\n",
        "try:\n",
        "    combined_data = pd.concat([region_df, customer_transactions.iloc[:, 4:]], axis=1)\n",
        "    if combined_data.isnull().any().any():\n",
        "        raise ValueError(\"Combined data contains NaN or infinite values.\")\n",
        "except ValueError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "bPV6xC_ZSpS_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data\n",
        "try:\n",
        "    scaler = StandardScaler()\n",
        "    normalized_data = scaler.fit_transform(combined_data)\n",
        "except Exception as e:\n",
        "    print(f\"Error during normalization: {e}\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "GPI8i11fSpMG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute similarity using cosine similarity\n",
        "try:\n",
        "    similarity_matrix = cosine_similarity(normalized_data)\n",
        "except Exception as e:\n",
        "    print(f\"Error during similarity calculation: {e}\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "HvGAFv_cSpJJ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find top 3 lookalike customers for each customer\n",
        "lookalike_results = {}\n",
        "customer_ids = customer_transactions['CustomerID'].tolist()\n",
        "\n",
        "for idx, customer_id in enumerate(customer_ids):\n",
        "    similarity_scores = list(enumerate(similarity_matrix[idx]))\n",
        "    sorted_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "    top_3 = [(customer_ids[i], round(score, 2)) for i, score in sorted_scores[1:4]]  # Exclude self (index 0)\n",
        "    lookalike_results[customer_id] = top_3"
      ],
      "metadata": {
        "id": "6r8vD3rgSpGW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results to Lookalike.csv\n",
        "try:\n",
        "    lookalike_df = pd.DataFrame({\n",
        "        'CustomerID': lookalike_results.keys(),\n",
        "        'Lookalikes': [str(v) for v in lookalike_results.values()]\n",
        "    })\n",
        "    lookalike_df.to_csv('Lookalike.csv', index=False)\n",
        "    print(\"Lookalike Model executed successfully. Results saved to Lookalike.csv.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving results: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU7nXgxZSpC_",
        "outputId": "2962ac3d-80aa-4b63-fe57-84ef38325eec"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lookalike Model executed successfully. Results saved to Lookalike.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "INWrOyzRSo_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e5HNjdHpSo8n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}